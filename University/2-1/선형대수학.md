*"개발자를 위한  실전 선형대수학" , "Linear Algibra"를 참고하여 만들었습니다.*

## 용어정리

- i : 단위행렬
- L : 하삼각행렬, 대각원소는 단위행렬처럼 1이고, 하삼각원소들은 -multiplier값으로 이루어져 있음
- U : 상삼각행렬
- P : formation matrix
- l : multiplier
- A^-1
	1. Gaussian Elimination에서 Ax = b -> x = A^-1 * b 꼴로 바꾸어 연산을 하기도 함
	2. 가우스-조던 방식을 통해 만들어짐

## 0. Python

```python
import numpy as np
import scipy.linalg as sc

#numpy
np.eye(n : int) #N x N 단위백터
np.allclose(arr1, arr2) # 동일여부판단

#np.linalg
np.linalg.dot(A,B) #AB내적
np.linalg.det(A) #determinant
np.linalg.norm(A) # ||A||
np.linalg.inv(A) # A^-1
np.linalg.solve(A, b) # x 해 구하기

#scipy.linalg
sc.LU(A) # P,L,U 반환
sc.solve_triangular(U, b, lower = True) #전위대입법
sc.solve_triangular(U, b, lower = False) #후위대입법

#번외
A.T #전치행렬
```

```python
#Gaussian Elimination
import copy
def gaussianElimination(A, b):

    U = copy.deepcopy(A)
    c = copy.deepcopy(b)

    for i in range(0, len(U)-1):
        for j in range(i+1, len(U)):
            multiplier = U[j][i] / U[i][i]
            for k in range(0, len(c[i])):
                c[j][k] -= c[i][k] * multiplier
            for k in range(0, len(U[i])):
                U[j][k] -= U[i][k] * multiplier

    return U, c
```

```python
#inverse matrix
def inverseMatrix(A):
    #역함수 존재x
    if(np.linalg.det(A) == 0): return -1
    l = len(A)
    I = np.eye(l)
    inverseA = copy.deepcopy(A)
    
    for i in range(0, l-1):
        for j in range(i+1, l):
            if(inverseA[i][i] != 0):
                multiplier = inverseA[j][i]/inverseA[i][i]
                for k in range(0, l):
                    inverseA[j][k] -= inverseA[i][k] * multiplier
                    I[j][k] -= I[i][k] * multiplier
  
    for i in range(l-1, -1, -1):
        for j in range(i-1, -1, -1):
            if(inverseA[i][i] != 0):
                multiplier = inverseA[j][i] / inverseA[i][i]
                for k in range(0, l):
                    inverseA[j][k] -= inverseA[i][k] * multiplier
                    I[j][k] -= I[i][k] * multiplier
  
    for i in range(0, l):
        if(inverseA[i][i] != 0):
            multiplier = inverseA[i][i]
            for j in range(0, l):
                I[i][j] /= multiplier
  
    return I
```

```python
#LU-Factorization
def slu(A):
    l = len(A)
    L = np.eye(l)
    U = A
  
    for i in range(0, len(U)-1):
        for j in range(i+1, len(U)):
            multiplier = U[j][i] / U[i][i]
            L[j][i] = multiplier
            for k in range(0, len(U[i])):
                U[j][k] -= U[i][k] * multiplier
  
    return L, U
```


## 1. 선형대수학

#### 기본 연산
- Add Vector : v+w
- Multiple Vector : cv, dw (c,d : real number scalar)
- Linear Combination : cv + dw
	- sum : 1v + 1w
	- sub : 1v - 1w
	- zero vector : 0v + 0w
	- scalar multiple : cv + dw

--- 

- 차원은 행의 개수를 의미한다
	n-dim(n차원 행렬)
- Z = zero vector
- remark (linear combinatiion) : 상호독립적(independence)가 성립해야 가능
	- v : linear
	- v + w : plane(2-dim)
	- v + w + u : space(3-dim)
- 보통 a = (1,2,3)은
$$
a =

\begin{bmatrix}

1\\

2\\

3

\end{bmatrix}

  $$
b = [1,2,3]은
$$
b =

\begin{bmatrix}

1,2,3\\

\end{bmatrix}

$$  을 의미한다




---

#### 내적(dot product | inner product)
- v * w = v1w1 + v2w2 + ... + vnwn
- 앞 벡터의 열의 개수와 뒷 벡터의 행의 개수가 일치해야만 내적 가능 
$$

\begin{bmatrix}

1 & 2 & 3 \\

4 & 5 & 6 \\

7 & 8 & 9

\end{bmatrix}

$$  
$$

\begin{bmatrix}

1 \\

0 \\

-1

\end{bmatrix}

$$
위 두 행렬의 곱(내적)
$$
  

Ax =

\begin{bmatrix}

(1)(1) + (2)(0) + (3)(-1) \\

(4)(1) + (5)(0) + (6)(-1) \\

(7)(1) + (8)(0) + (9)(-1)

\end{bmatrix}

  

\begin{bmatrix}

1 + 0 - 3 \\

4 + 0 - 6 \\

7 + 0 - 9

\end{bmatrix}

  

\begin{bmatrix}

-2 \\

-2 \\

-2

\end{bmatrix}
$$


#### 단위 벡터/행렬
- length/norm(벡터의 길이) : ||v|| = math.sqrt(v1v1 + v2v2 + ... + vnvn)
- unit vector(단위 벡터) : ||U|| = 1인 벡터 U를 단위벡터
	- V = (cos t, sin t)와 같이 길이가 1인 벡터들
- U = V / ||V|| -> 벡터 V의 모든 원소에 norm(V)를 나누어 주면 길이가 1인 단위벡터가 생성된다.
*이때 U는 V에 종속적이다. U ∈ V*


#### Relationship with angle
- v * w = 0  : angle = 90
- v * w > 0  : angle < 90
- v * w < 0  : angle > 90
- U * u = vw / ||v|| ||w|| = cos t(두 단위벡터의 내적은 cos t이다.) -> | u * U | <= 1
- t = (cos (u * U))^-1 
- schwarz inequality : |vw| <= ||v|| ||w||
- triangle inequality : ||v+w|| <= ||v|| + ||w||
- 반드시 삼각함수를 사용하기 전에 단위벡터로 바꾸어서 사용
- Z는 모든 벡터와 직각


## 선형방정식의 해

#### matrix notation 
- a(i, j) = a ij(i는 행, j는 열)
- Identity Matrix(단위행렬) : n x n 행렬중에 대각원소가 1, 이외의 원소가 모두 0인 행렬
- 소거법 : 미지수를 행렬로 표현한 a,b에 대해 미지수의 값을 구해 해를 찾는 방식 (가우스 소거법)
	- upper triangle systme/matrix(U) : 상삼각 행렬, 대각 포함하지 않은 아래 원소를 0으로 바꿈 
	- Back substitution
- Pivot : 기준, 위 상삼각 행렬에서 소거를 하려는 행 중 처음으로 0이 아닌 원소
- Determinant : 모든 행의 pivot을 곱한 값 (determinant = 0일 경우 unique solution이 존재하지 않음)
- mulitplier : 승수, pivot으로 나눈 값 -> l21(2행 1열)
- 따라서 upper triangle matrix를 풀기 위해 mn행렬은 n개의 pivot이 필요하다.
- 추가로 가우스 소거법을 통해 unique solution을 찾을 때(하나 뿐인 해), 1. determinant가 존재하지 않는다. 2. 역행렬이 존재하지 않는다. 중 하나라도 해당되는 행렬일 경우 unique solution이 존재하지 않는다. 

#### 소거행렬
- 가우스 소거법 back substitution을 통해 해를 찾음
- 단위행렬에 l(mutiplier)가 존재할경우 l을 지워주는 작업
	- Ax = b -> EAx = Eb(대각선 아래 값을 0으로 바꿔주는 것 = E)
- 일반적으로 AB != BA이다(특수하게 AA^-1 = A^-1A = U이다.)

#### 가우스 소거법
- Ax = b 를 Ux = c꼴로 바꾸어 후위대입법(Back Substitution)을 통해 소거하는 방법

#### 가우스-조던(역행렬)

- [A | I]를 통해 I를 A^-1로 만드는 방식 

#### LU 분해
- PA = LU꼴로 분해. 이때 행교환이 없는 행렬일경우 P는 단위백터
- A = LU꼴로 분해도 가능

#### LDU 분해
- LU를 LDU로 분해한 꼴
- 이때 L은 건드리지 않고, U = DU'골로 변하게 하는데, D는 U의 대각원소만 넣고, 나머지 원소는 0으로 채운다.
- 이후 U' = D^-1 * U(내적)을 통해 U'을 만들어준다.

#### 전치행렬
- 원소의 행과 열의 위치를 바꾸는것
- 즉 a21 ^ T = a12로 위치하게 된다.
- A.T를 통해 구현

#### 행교환
A=LU꼴이 아닌 PA=LU꼴로 분해되며, sc.lu()를 하게 되면 P,L,U가 리턴된다.

####