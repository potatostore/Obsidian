*"개발자를 위한  실전 선형대수학" , "Linear Algibra"를 참고하여 만들었습니다.*

## 용어정리

- i : 단위행렬
- L : 하삼각행렬, 대각원소는 단위행렬처럼 1이고, 하삼각원소들은 -multiplier값으로 이루어져 있음
- U : 상삼각행렬
- P : formation matrix
- l : multiplier
- A^-1
	1. Gaussian Elimination에서 Ax = b -> x = A^-1 * b 꼴로 바꾸어 연산을 하기도 함
	2. 가우스-조던 방식을 통해 만들어짐

## 0. Python

```python
import numpy as np
import scipy.linalg as sc

#numpy
np.eye(n : int) #N x N 단위백터
np.allclose(arr1, arr2) # 동일여부판단

#np.linalg
np.linalg.dot(A,B) #AB내적
np.linalg.det(A) #determinant
np.linalg.norm(A) # ||A||
np.linalg.inv(A) # A^-1
np.linalg.solve(A, b) # x 해 구하기

#scipy.linalg
sc.LU(A) # P,L,U 반환
sc.solve_triangular(U, b, lower = True) #전위대입법
sc.solve_triangular(U, b, lower = False) #후위대입법

#번외
A.T #전치행렬
```

```python
#PA = LU
import numpy as np

def lu_decomposition_with_pivoting(A):
    n = len(A)
    A = A.astype(float)
    P = np.eye(n)
    L = np.zeros((n, n))
    U = A.copy()

    for i in range(n):
        max_row = np.argmax(np.abs(U[i:, i])) + i

        if i != max_row:
            U[[i, max_row]] = U[[max_row, i]]
            P[[i, max_row]] = P[[max_row, i]]
            if i > 0:
                L[[i, max_row], :i] = L[[max_row, i], :i]

        for j in range(i+1, n):
            L[j][i] = U[j][i] / U[i][i]
            U[j] -= L[j][i] * U[i]

        L[i][i] = 1  

    return P, L, U
```

```python
#Gaussian Elimination
import copy
def gaussianElimination(A, b):

    U = copy.deepcopy(A)
    c = copy.deepcopy(b)

    for i in range(0, len(U)-1):
        for j in range(i+1, len(U)):
            multiplier = U[j][i] / U[i][i]
            for k in range(0, len(c[i])):
                c[j][k] -= c[i][k] * multiplier
            for k in range(0, len(U[i])):
                U[j][k] -= U[i][k] * multiplier

    return U, c
```

```python
#Back substitution / Forward substitution
for i in range(n - 1, -1, -1): # (0, n)으로 바꾸면 Forward substitution
        sum_ax = sum(U[i][j] * x[j] for j in range(i + 1, n))
        x[i] = (c[i] - sum_ax) / U[i][i]
```

```python
#inverse matrix(Gauss-Jordan)
def inverseMatrix(A):
    #역함수 존재x
    if(np.linalg.det(A) == 0): return -1
    l = len(A)
    I = np.eye(l)
    inverseA = copy.deepcopy(A)
    
    for i in range(0, l-1):
        for j in range(i+1, l):
            if(inverseA[i][i] != 0):
                multiplier = inverseA[j][i]/inverseA[i][i]
                for k in range(0, l):
                    inverseA[j][k] -= inverseA[i][k] * multiplier
                    I[j][k] -= I[i][k] * multiplier
  
    for i in range(l-1, -1, -1):
        for j in range(i-1, -1, -1):
            if(inverseA[i][i] != 0):
                multiplier = inverseA[j][i] / inverseA[i][i]
                for k in range(0, l):
                    inverseA[j][k] -= inverseA[i][k] * multiplier
                    I[j][k] -= I[i][k] * multiplier
  
    for i in range(0, l):
        if(inverseA[i][i] != 0):
            multiplier = inverseA[i][i]
            for j in range(0, l):
                I[i][j] /= multiplier
  
    return I
```

```python
#LU-Factorization
#PA = LU꼴은 sc.lu()사용하기기
def slu(A):
    l = len(A)
    L = np.eye(l)
    U = A
  
    for i in range(0, len(U)-1):
        for j in range(i+1, len(U)):
            multiplier = U[j][i] / U[i][i]
            L[j][i] = multiplier
            for k in range(0, len(U[i])):
                U[j][k] -= U[i][k] * multiplier
  
    return L, U
```

```python
#LUx = b꼴 해 구하기
def slv(L, U, b):
    x = []
    y = []

    y = sc.solve_triangular(L, b, lower=True)
    x = sc.solve_triangular(U, y)

    return x
```


## 1. 선형대수학

#### 기본 연산
- Add Vector : v+w
- Multiple Vector : cv, dw (c,d : real number scalar)
- Linear Combination : cv + dw
	- sum : 1v + 1w
	- sub : 1v - 1w
	- zero vector : 0v + 0w
	- scalar multiple : cv + dw

--- 

- 차원은 행의 개수를 의미한다
	n-dim(n차원 행렬)
- Z = zero vector
- remark (linear combinatiion) : 상호독립적(independence)가 성립해야 가능
	- v : linear
	- v + w : plane(2-dim)
	- v + w + u : space(3-dim)
- 보통 a = (1,2,3)은
$$
a =

\begin{bmatrix}

1\\

2\\

3

\end{bmatrix}

  $$
b = [1,2,3]은
$$
b =

\begin{bmatrix}

1,2,3\\

\end{bmatrix}

$$  을 의미한다




---

#### 내적(dot product | inner product)
- v * w = v1w1 + v2w2 + ... + vnwn
- 앞 벡터의 열의 개수와 뒷 벡터의 행의 개수가 일치해야만 내적 가능 
$$

\begin{bmatrix}

1 & 2 & 3 \\

4 & 5 & 6 \\

7 & 8 & 9

\end{bmatrix}

$$  
$$

\begin{bmatrix}

1 \\

0 \\

-1

\end{bmatrix}

$$
위 두 행렬의 곱(내적)
$$
  

Ax =

\begin{bmatrix}

(1)(1) + (2)(0) + (3)(-1) \\

(4)(1) + (5)(0) + (6)(-1) \\

(7)(1) + (8)(0) + (9)(-1)

\end{bmatrix}

  

\begin{bmatrix}

1 + 0 - 3 \\

4 + 0 - 6 \\

7 + 0 - 9

\end{bmatrix}

  

\begin{bmatrix}

-2 \\

-2 \\

-2

\end{bmatrix}
$$


#### 단위 벡터/행렬
- length/norm(벡터의 길이) : ||v|| = math.sqrt(v1v1 + v2v2 + ... + vnvn)
- unit vector(단위 벡터) : ||U|| = 1인 벡터 U를 단위벡터
	- V = (cos t, sin t)와 같이 길이가 1인 벡터들
- U = V / ||V|| -> 벡터 V의 모든 원소에 norm(V)를 나누어 주면 길이가 1인 단위벡터가 생성된다.
*이때 U는 V에 종속적이다. U ∈ V*


#### Relationship with angle
- v * w = 0  : angle = 90
- v * w > 0  : angle < 90
- v * w < 0  : angle > 90
- U * u = vw / ||v|| ||w|| = cos t(두 단위벡터의 내적은 cos t이다.) -> | u * U | <= 1
- t = (cos (u * U))^-1 
- schwarz inequality : |vw| <= ||v|| ||w||
- triangle inequality : ||v+w|| <= ||v|| + ||w||
- 반드시 삼각함수를 사용하기 전에 단위벡터로 바꾸어서 사용
- Z는 모든 벡터와 직각


## 선형방정식의 해

#### matrix notation 
- a(i, j) = a ij(i는 행, j는 열)
- Identity Matrix(단위행렬) : n x n 행렬중에 대각원소가 1, 이외의 원소가 모두 0인 행렬
- 소거법 : 미지수를 행렬로 표현한 a,b에 대해 미지수의 값을 구해 해를 찾는 방식 (가우스 소거법)
	- upper triangle systme/matrix(U) : 상삼각 행렬, 대각 포함하지 않은 아래 원소를 0으로 바꿈 
	- Back substitution
- Pivot : 기준, 위 상삼각 행렬에서 소거를 하려는 행 중 처음으로 0이 아닌 원소
- Determinant : 모든 행의 pivot을 곱한 값 (determinant = 0일 경우 unique solution이 존재하지 않음)
- mulitplier : 승수, pivot으로 나눈 값 -> l21(2행 1열)
- 따라서 upper triangle matrix를 풀기 위해 mn행렬은 n개의 pivot이 필요하다.
- 추가로 가우스 소거법을 통해 unique solution을 찾을 때(하나 뿐인 해), 1. determinant가 존재하지 않는다. 2. 역행렬이 존재하지 않는다. 중 하나라도 해당되는 행렬일 경우 unique solution이 존재하지 않는다. 

#### 소거행렬
- 가우스 소거법 back substitution을 통해 해를 찾음
- 단위행렬에 l(mutiplier)가 존재할경우 l을 지워주는 작업
	- Ax = b -> EAx = Eb(대각선 아래 값을 0으로 바꿔주는 것 = E)
- 일반적으로 AB != BA이다(특수하게 AA^-1 = A^-1A = U이다.)

#### 가우스 소거법
- Ax = b 를 Ux = c꼴로 바꾸어 후위대입법(Back Substitution)을 통해 소거하는 방법

#### 가우스-조던(역행렬)

- [A | I]를 통해 I를 A^-1로 만드는 방식 

#### LU 분해
- PA = LU꼴로 분해. 이때 행교환이 없는 행렬일경우 P는 단위백터
- A = LU꼴로 분해도 가능

#### LDU 분해
- LU를 LDU로 분해한 꼴
- 이때 L은 건드리지 않고, U = DU'골로 변하게 하는데, D는 U의 대각원소만 넣고, 나머지 원소는 0으로 채운다.
- 이후 U' = D^-1 * U(내적)을 통해 U'을 만들어준다.

#### 전치행렬
- 원소의 행과 열의 위치를 바꾸는것
- 즉 a21 ^ T = a12로 위치하게 된다.
- A.T를 통해 구현

#### 행교환
A=LU꼴이 아닌 PA=LU꼴로 분해되며, sc.lu()를 하게 되면 P,L,U가 리턴된다. 이때 P^-1 = P.T는 항상 성립하지만 P = P^-1이 되기 위해서는 P가 대칭행렬, 즉 P = P.T가 되어야 성립한다.

---

- 현재 중간고사까지 핵심은 x의 해를 소거법을 통해서 구하는 방식이다.
- Ax = b꼴과 같이 다항연립방정식의 해를 행렬을 통해 구하는 것이 중요하다.
- x값이 unique solution(단 하나의 해)을 갖기 위해선
	1. A의 각 열이 독립일 때
	2. Ax = b를 Ux = c로 가우스 소거시, U의 대각원소, 즉 pivot의 값들이 0이 아니여야 한다.(pivot의 개수가 len(A)개 여야 한다.)
	3. U의 대각원소의 곱(determinant != 0)
	4. Ax = 0일때, x가 0 이외의 값을 갖지 않아야 한다
	5. A의 역행렬이 존재할 때
	와 같이 총 5경우의 수가 존재한다.
- x의 해를 구하는 방법은 다음과 같다.
	1. 가우스 소거(Ax = b -> Ux = c) + 후위대입법
	2. 가우스-조던을 통해 inv(A)구한 후 x = A^-1 * b를 통해 해 구하기
	3. LU분해 이용하기
		1. A = LU(혹은 A = P^-1LU)
		2. (P^-1)LUx = b
		3. Ux = y
		4. Ly = Pb
		5. L은 하삼각행렬이므로 y의 해를 전위대입법을 통해 구하기
		6. Ux = y에 위 해를 대입하여 후위대입법으로 x구하기


## 벡터공간 / 부분공간

#### Vector Space

- 벡터의 합, 스칼라 곱을 통해 표현할 수 있는 모든 벡터를 벡터공간이라고 함
- 규칙
	- x + y = y + x (교환법칙)
	- x + (y + z) = (x + y) + z
	- x+ 0 = x를 만족하는 0는 단 하나만 존재한다
	- x + (-x) = 0
	- 1 * x = x
	- (c1 * c2) * x = c1 * (c2 * x) (결합법칙)
	- c * (x + y) = cx + cy(분배법칙)
- 반드시 0벡터를 포함하고 있어야 벡터공간으로 인정함

#### SubSpace

- 벡터(R^3 일 경우 벡터 x = [x1,x2,x3])가 원점을 지나는 벡터일 경우 그 벡터의 경로 상에 표현될 수 있는 모든 벡터를 부분 공간이라고 함.
- 또한 선형조합 (cx + dy)와 같이 두 벡터와 스칼라 곱을 통해 조합되는 경우 만들어 질 수 있는 모든 평면 벡터(R^3일 경우 두 벡터의 선형 조합을 통해 최대 2차원 평면 부분 공간)을 만들 수 있다.(단 항상 원점을 지나야 함.)
- zero vector(0,0,0)
- 공간 전체(R^3에서 표현할 수 있는 모든 벡터)

위 4개의 경우를 모두 부분공간이라고 함.

#### Column Space (C(A))

가우스 소거법을 통해 x의 유니크 해를 찾았다면 column space를 통해 Ax의 Subspace를 표현하고, subspace에 b벡터가 있는지 판별하여 해가 있는지 없는지 판별하는 방식이다.

*span : S가 vector space의 V의 아무 벡터를 가르킬 때, S의 모든 선형 조합을 SS라고 가정을 한다. 즉 SS는 Subspace가 되고, SS는 S에 "span"된다 라고 말을 한다. (즉 어떤 Subspace내부에 포함된 벡터를 Subspace가 해당 벡터에 Span한다 라고 말함.*


#### Null Space (N(A))

 가우스 소거법을 통해 상삼각행렬(nxn행렬에서 pivot이 n개인 행렬)을 만들 수 있으면 1개의 해(unique solution)이 만들어 짐. 하지만 가우스 소거법을 진행했는데 상삼각행렬이 만들어지지 않게 되었을 경우 여러 해가 만들어 지는데 이를 *Special Solution*이라고 한다. 이와 같은 경우 해가 Subspace로 나타나고, 해당 Subspace위에 나타낼 수 있는 모든 벡터가 해가 될 수 있다.
 
free variable(자유변수) : pivot이 없는 열
pivot variable : pivot이 있는 열

푸는 방법은 기존 가우스 소거법과 동일 (이때 b=0인 x의 해를 찾는 것이다.)
1. Forward Elimination : E21, E31 ... 등을 통해 상삼각행렬 U 생성
2. Back Substitution : Ux = 0을 후위대입법을 통해 solution 찾기(이때 unique solution이 아닌 경우 U가 나올 수 없으므로 R(행 사다리꼴 행렬 - RRef)이라고 함.)

즉 N(A) = N(U) = N(R) = N(rref(A)) = 0인 경우를 찾는게 Null Space이다.

- 해가 0벡터일 경우 행렬 A의 각 열은 독립적이다.(0 이외의 해가 존재하지 않기 때문)
- 자유변수의 개수만큼 special solution이 존재
- 자유변수가 존재하지 않는 경우(special solution이 존재 x), A(x) = N(A) = Z
- Rx = 0꼴에서 자유변수에 값