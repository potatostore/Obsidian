*"개발자를 위한  실전 선형대수학" , "Linear Algibra"를 참고하여 만들었습니다.*

## 용어정리

- i : 단위행렬
- L : 하삼각행렬, 대각원소는 단위행렬처럼 1이고, 하삼각원소들은 -multiplier값으로 이루어져 있음
- U : 상삼각행렬
- P : formation matrix
- l : multiplier
- A^-1
	1. Gaussian Elimination에서 Ax = b -> x = A^-1 * b 꼴로 바꾸어 연산을 하기도 함
	2. 가우스-조던 방식을 통해 만들어짐

## 0. Python

```python
import numpy as np
import scipy.linalg as sc

#numpy
np.eye(n : int) #N x N 단위백터
np.allclose(arr1, arr2) # 동일여부판단

#np.linalg
np.linalg.dot(A,B) #AB내적
np.linalg.det(A) #determinant
np.linalg.norm(A) # ||A||
np.linalg.inv(A) # A^-1
np.linalg.solve(A, b) # x 해 구하기

#scipy.linalg
sc.LU(A) # P,L,U 반환
sc.solve_triangular(U, b, lower = True) #전위대입법
sc.solve_triangular(U, b, lower = False) #후위대입법

#번외
A.T #전치행렬
```

```python
#PA = LU
import numpy as np

def lu_decomposition_with_pivoting(A):
    n = len(A)
    A = A.astype(float)
    P = np.eye(n)
    L = np.zeros((n, n))
    U = A.copy()

    for i in range(n):
        max_row = np.argmax(np.abs(U[i:, i])) + i

        if i != max_row:
            U[[i, max_row]] = U[[max_row, i]]
            P[[i, max_row]] = P[[max_row, i]]
            if i > 0:
                L[[i, max_row], :i] = L[[max_row, i], :i]

        for j in range(i+1, n):
            L[j][i] = U[j][i] / U[i][i]
            U[j] -= L[j][i] * U[i]

        L[i][i] = 1  

    return P, L, U
```

```python
#Gaussian Elimination
import copy
def gaussianElimination(A, b):

    U = copy.deepcopy(A)
    c = copy.deepcopy(b)

    for i in range(0, len(U)-1):
        for j in range(i+1, len(U)):
            multiplier = U[j][i] / U[i][i]
            for k in range(0, len(c[i])):
                c[j][k] -= c[i][k] * multiplier
            for k in range(0, len(U[i])):
                U[j][k] -= U[i][k] * multiplier

    return U, c
```

```python
#Back substitution / Forward substitution
for i in range(n - 1, -1, -1): # (0, n)으로 바꾸면 Forward substitution
        sum_ax = sum(U[i][j] * x[j] for j in range(i + 1, n))
        x[i] = (c[i] - sum_ax) / U[i][i]
```

```python
#inverse matrix(Gauss-Jordan)
def inverseMatrix(A):
    #역함수 존재x
    if(np.linalg.det(A) == 0): return -1
    l = len(A)
    I = np.eye(l)
    inverseA = copy.deepcopy(A)
    
    for i in range(0, l-1):
        for j in range(i+1, l):
            if(inverseA[i][i] != 0):
                multiplier = inverseA[j][i]/inverseA[i][i]
                for k in range(0, l):
                    inverseA[j][k] -= inverseA[i][k] * multiplier
                    I[j][k] -= I[i][k] * multiplier
  
    for i in range(l-1, -1, -1):
        for j in range(i-1, -1, -1):
            if(inverseA[i][i] != 0):
                multiplier = inverseA[j][i] / inverseA[i][i]
                for k in range(0, l):
                    inverseA[j][k] -= inverseA[i][k] * multiplier
                    I[j][k] -= I[i][k] * multiplier
  
    for i in range(0, l):
        if(inverseA[i][i] != 0):
            multiplier = inverseA[i][i]
            for j in range(0, l):
                I[i][j] /= multiplier
  
    return I
```

```python
#LU-Factorization
#PA = LU꼴은 sc.lu()사용하기기
def slu(A):
    l = len(A)
    L = np.eye(l)
    U = A
  
    for i in range(0, len(U)-1):
        for j in range(i+1, len(U)):
            multiplier = U[j][i] / U[i][i]
            L[j][i] = multiplier
            for k in range(0, len(U[i])):
                U[j][k] -= U[i][k] * multiplier
  
    return L, U
```

```python
#LUx = b꼴 해 구하기
def slv(L, U, b):
    x = []
    y = []

    y = sc.solve_triangular(L, b, lower=True)
    x = sc.solve_triangular(U, y)

    return x
```


## 1. 선형대수학

#### 기본 연산
- Add Vector : v+w
- Multiple Vector : cv, dw (c,d : real number scalar)
- Linear Combination : cv + dw
	- sum : 1v + 1w
	- sub : 1v - 1w
	- zero vector : 0v + 0w
	- scalar multiple : cv + dw

--- 

- 차원은 행의 개수를 의미한다
	n-dim(n차원 행렬)
- Z = zero vector
- remark (linear combinatiion) : 상호독립적(independence)가 성립해야 가능
	- v : linear
	- v + w : plane(2-dim)
	- v + w + u : space(3-dim)
- 보통 a = (1,2,3)은
$$
a =

\begin{bmatrix}

1\\

2\\

3

\end{bmatrix}

  $$
b = [1,2,3]은
$$
b =

\begin{bmatrix}

1,2,3\\

\end{bmatrix}

$$  을 의미한다




---

#### 내적(dot product | inner product)
- v * w = v1w1 + v2w2 + ... + vnwn
- 앞 벡터의 열의 개수와 뒷 벡터의 행의 개수가 일치해야만 내적 가능 
$$

\begin{bmatrix}

1 & 2 & 3 \\

4 & 5 & 6 \\

7 & 8 & 9

\end{bmatrix}

$$  
$$

\begin{bmatrix}

1 \\

0 \\

-1

\end{bmatrix}

$$
위 두 행렬의 곱(내적)
$$
  

Ax =

\begin{bmatrix}

(1)(1) + (2)(0) + (3)(-1) \\

(4)(1) + (5)(0) + (6)(-1) \\

(7)(1) + (8)(0) + (9)(-1)

\end{bmatrix}

  

\begin{bmatrix}

1 + 0 - 3 \\

4 + 0 - 6 \\

7 + 0 - 9

\end{bmatrix}

  

\begin{bmatrix}

-2 \\

-2 \\

-2

\end{bmatrix}
$$


#### 단위 벡터/행렬
- length/norm(벡터의 길이) : ||v|| = math.sqrt(v1v1 + v2v2 + ... + vnvn)
- unit vector(단위 벡터) : ||U|| = 1인 벡터 U를 단위벡터
	- V = (cos t, sin t)와 같이 길이가 1인 벡터들
- U = V / ||V|| -> 벡터 V의 모든 원소에 norm(V)를 나누어 주면 길이가 1인 단위벡터가 생성된다.
*이때 U는 V에 종속적이다. U ∈ V*


#### Relationship with angle
- v * w = 0  : angle = 90
- v * w > 0  : angle < 90
- v * w < 0  : angle > 90
- U * u = vw / ||v|| ||w|| = cos t(두 단위벡터의 내적은 cos t이다.) -> | u * U | <= 1
- t = (cos (u * U))^-1 
- schwarz inequality : |vw| <= ||v|| ||w||
- triangle inequality : ||v+w|| <= ||v|| + ||w||
- 반드시 삼각함수를 사용하기 전에 단위벡터로 바꾸어서 사용
- Z는 모든 벡터와 직각


## 선형방정식의 해

#### matrix notation 
- a(i, j) = a ij(i는 행, j는 열)
- Identity Matrix(단위행렬) : n x n 행렬중에 대각원소가 1, 이외의 원소가 모두 0인 행렬
- 소거법 : 미지수를 행렬로 표현한 a,b에 대해 미지수의 값을 구해 해를 찾는 방식 (가우스 소거법)
	- upper triangle systme/matrix(U) : 상삼각 행렬, 대각 포함하지 않은 아래 원소를 0으로 바꿈 
	- Back substitution
- Pivot : 기준, 위 상삼각 행렬에서 소거를 하려는 행 중 처음으로 0이 아닌 원소
- Determinant : 모든 행의 pivot을 곱한 값 (determinant = 0일 경우 unique solution이 존재하지 않음)
- mulitplier : 승수, pivot으로 나눈 값 -> l21(2행 1열)
- 따라서 upper triangle matrix를 풀기 위해 mn행렬은 n개의 pivot이 필요하다.
- 추가로 가우스 소거법을 통해 unique solution을 찾을 때(하나 뿐인 해), 1. determinant가 존재하지 않는다. 2. 역행렬이 존재하지 않는다. 중 하나라도 해당되는 행렬일 경우 unique solution이 존재하지 않는다. 

#### 소거행렬
- 가우스 소거법 back substitution을 통해 해를 찾음
- 단위행렬에 l(mutiplier)가 존재할경우 l을 지워주는 작업
	- Ax = b -> EAx = Eb(대각선 아래 값을 0으로 바꿔주는 것 = E)
- 일반적으로 AB != BA이다(특수하게 AA^-1 = A^-1A = U이다.)

#### 가우스 소거법
- Ax = b 를 Ux = c꼴로 바꾸어 후위대입법(Back Substitution)을 통해 소거하는 방법

#### 가우스-조던(역행렬, inverse matrix)

- [A | I]를 통해 I를 A^-1로 만드는 방식 

#### LU 분해
- PA = LU꼴로 분해. 이때 행교환이 없는 행렬일경우 P는 단위백터
- A = LU꼴로 분해도 가능

#### LDU 분해
- LU를 LDU로 분해한 꼴
- 이때 L은 건드리지 않고, U = DU'골로 변하게 하는데, D는 U의 대각원소만 넣고, 나머지 원소는 0으로 채운다.
- 이후 U' = D^-1 * U(내적)을 통해 U'을 만들어준다.

#### 전치행렬(transpose)
- 원소의 행과 열의 위치를 바꾸는것
- 즉 a21 ^ T = a12로 위치하게 된다.
- A.T를 통해 구현

#### 행교환
A=LU꼴이 아닌 PA=LU꼴로 분해되며, sc.lu()를 하게 되면 P,L,U가 리턴된다. 이때 P^-1 = P.T는 항상 성립하지만 P = P^-1이 되기 위해서는 P가 대칭행렬, 즉 P = P.T가 되어야 성립한다.

---

- 현재 중간고사까지 핵심은 x의 해를 소거법을 통해서 구하는 방식이다.
- Ax = b꼴과 같이 다항연립방정식의 해를 행렬을 통해 구하는 것이 중요하다.
- x값이 unique solution(단 하나의 해)을 갖기 위해선
	1. A의 각 열이 독립일 때
	2. Ax = b를 Ux = c로 가우스 소거시, U의 대각원소, 즉 pivot의 값들이 0이 아니여야 한다.(pivot의 개수가 len(A)개 여야 한다.)
	3. U의 대각원소의 곱(determinant != 0)
	4. Ax = 0일때, x가 0 이외의 값을 갖지 않아야 한다
	5. A의 역행렬이 존재할 때
	와 같이 총 5경우의 수가 존재한다.
- x의 해를 구하는 방법은 다음과 같다.
	1. 가우스 소거(Ax = b -> Ux = c) + 후위대입법
	2. 가우스-조던을 통해 inv(A)구한 후 x = A^-1 * b를 통해 해 구하기
	3. LU분해 이용하기
		1. A = LU(혹은 A = P^-1LU)
		2. (P^-1)LUx = b
		3. Ux = y
		4. Ly = Pb
		5. L은 하삼각행렬이므로 y의 해를 전위대입법을 통해 구하기
		6. Ux = y에 위 해를 대입하여 후위대입법으로 x구하기


# 벡터공간 / 부분공간

## Vector Space

- 벡터의 합, 스칼라 곱을 통해 표현할 수 있는 모든 벡터를 벡터공간이라고 함
- 규칙
	- x + y = y + x (교환법칙)
	- x + (y + z) = (x + y) + z
	- x+ 0 = x를 만족하는 0는 단 하나만 존재한다
	- x + (-x) = 0
	- 1 * x = x
	- (c1 * c2) * x = c1 * (c2 * x) (결합법칙)
	- c * (x + y) = cx + cy(분배법칙)
- 반드시 0벡터를 포함하고 있어야 벡터공간으로 인정함

## SubSpace

- 벡터(R^3 일 경우 벡터 x = [x1,x2,x3])가 원점을 지나는 벡터일 경우 그 벡터의 경로 상에 표현될 수 있는 모든 벡터를 부분 공간이라고 함.
- 또한 선형조합 (cx + dy)와 같이 두 벡터와 스칼라 곱을 통해 조합되는 경우 만들어 질 수 있는 모든 평면 벡터(R^3일 경우 두 벡터의 선형 조합을 통해 최대 2차원 평면 부분 공간)을 만들 수 있다.(단 항상 원점을 지나야 함.)
- zero vector(0,0,0)
- 공간 전체(R^3에서 표현할 수 있는 모든 벡터)

위 4개의 경우를 모두 부분공간이라고 함.

## Column Space (C(A))

가우스 소거법을 통해 x의 유니크 해를 찾았다면 column space를 통해 Ax의 Subspace를 표현하고, subspace에 b벡터가 있는지 판별하여 해가 있는지 없는지 판별하는 방식이다.

*span : S가 vector space의 V의 아무 벡터를 가르킬 때, S의 모든 선형 조합을 SS라고 가정을 한다. 즉 SS는 Subspace가 되고, SS는 S에 "span"된다 라고 말을 한다. (즉 어떤 Subspace내부에 포함된 벡터를 Subspace가 해당 벡터에 Span한다 라고 말함. 즉 공간을 생성한다라는 개념*

## Null Space의 의미

#### 정의

- Null Space(영공간)는 선형 시스템 Ax = 0의 모든 해 x의 집합을 의미함
- 이는 벡터 공간이며, 행렬 A의 열벡터들의 선형 조합이 0이 되는 벡터들의 집합

#### 특징

- 항상 적어도 하나의 해(영벡터)를 가짐
- 자유변수가 존재할 경우 무수히 많은 해를 가짐
- Null Space는 Ax = 0의 해 공간(solution space)을 형성함

## RREF(행 사다리꼴)과 Null Space 구하기

#### Gaussian Elimination 과정

- 일반적인 선형 시스템에서는 상삼각행렬을 만들어 후진대입법으로 해를 구함
- 하지만 Null Space에서는 해가 unique하지 않을 수 있으므로, **RREF(행 사다리꼴, Reduced Row Echelon Form)**으로 바꾼 후 해를 표현

#### Rx = 0의 해 구하기

- 행 사다리꼴 행렬 R을 기준으로 Rx = 0의 해를 구함
- 피벗이 없는 열은 자유변수(free variable)가 됨
- 피벗이 있는 열은 피벗변수(pivot variable)로, 자유변수에 따라 값이 결정됨

## 자유변수를 통한 해의 표현

#### 자유변수 선택 이유

- 자유변수는 어떤 값이든 선택 가능하며, 그에 따라 피벗변수가 결정됨
- 이를 통해 Null Space의 **기저벡터(basis vector)**들을 구할 수 있음

#### 방법

- 자유변수가 2개면, 각 자유변수에 1을 주고 나머지는 0을 주는 방식으로 2번 반복
- 자유변수가 3개면, x2=1,x3=0,x4=0 / x2=0,x3=1,x4=0 / x2=0,x3=0,x4=1 식으로 3번 반복

## 기저벡터(Basis Vector)

#### 정의

- Null Space 전체를 선형결합으로 생성할 수 있는 최소 집합의 벡터들
- Null Space가 형성하는 *벡터공간의 '방향'을 대표하는 벡터들*

#### 특징

- Null Space의 차원(nullity)과 기저벡터의 개수는 같음
- 자유변수의 개수 = Null Space의 차원 = 기저벡터 개수
- 각 기저벡터는 독립(linearly independent)함

#### 예시

- Rx = 0의 행렬 R에서 자유변수 x2, x4가 있다면,
    - x2 = 1, x4 = 0을 대입해 x1 = -1 등으로 구함 → 첫 번째 기저벡터
    - x2 = 0, x4 = 1을 대입해 x1 = -1 등으로 구함 → 두 번째 기저벡터

## 정리

#### Null Space 해법 과정 요약

- 행렬 A에서 Ax = 0 꼴 설정
- 가우스 소거법으로 행 사다리꼴 행렬 R로 변환
- 자유변수 선택 (각 변수마다 단위벡터 대입)
- Rx = 0을 만족하는 해 벡터 x를 구함 → 이를 통해 기저벡터 형성

*이 과정을 통해 Null Space를 기저벡터들의 선형 결합으로 표현 가능*

#### Null Space 관련 용어 요약

- *Null Space*: Ax = 0을 만족하는 모든 x의 집합
- *기저벡터*: Null Space를 생성하는 최소 독립 벡터 집합
- *자유변수*: 해가 자유롭게 선택되는 변수로, 기저벡터 결정에 사용됨
- *RREF(R)*: 행 사다리꼴 행렬로, Rx = 0 해를 찾는 데 사용


# Rank와 Null Space의 관계

## Rank의 정의와 기본 성질

#### Rank란?

- 어떤 행렬 A의 rank는 그 행렬의 **pivot(피벗)**의 개수를 의미함
- 즉, _rank(A) = 피벗의 개수 = r_

#### Rank 관련 등식

- _rank(A) = r = 독립적인 행의 개수 = 독립적인 열의 개수 = Column Space의 차원_
- r은 A의 행 수 m과 열 수 n을 기준으로 다음을 만족함:
    - _r ≤ m_, _r ≤ n_

#### Rank의 유형

- _r = m_이면: full row rank (모든 행이 독립적)
- _r = n_이면: full column rank (모든 열이 독립적)

## Rank와 Null Space의 관계

#### 자유변수와 special solution
- 자유변수의 개수 = n - r
- 자유변수 하나마다 하나의 special solution이 존재함
- 즉, _Null Space N(A)는 (n - r)개의 special solution으로 생성된 벡터공간_

#### Null Space의 의미

- _N(A) = Ax = 0_을 만족하는 모든 해 x의 집합
- 자유변수들에 따라 달라지는 해의 조합은 모두 Null Space의 원소
- 이는 _N(A)는 (n - r)개의 special solution이 만드는 span_임

## Column Space와 Row Space

#### Column Space C(A)
- 열벡터들로 생성되는 벡터공간
- _dim(C(A)) = rank(A) = r_

#### Row Space

- A의 행들로 생성되는 벡터공간
- _Aᵀ의 열공간 = A의 행공간_
- 즉, 전치행렬 Aᵀ을 통해 Row Space를 열벡터 관점으로 볼 수 있음

## Rank가 1일 때의 특성

#### Rank = 1

- 단 하나의 pivot만 존재
- 그 pivot이 속한 행벡터 하나로 나머지 행벡터들을 생성 가능 (선형결합)
- 마찬가지로, pivot이 속한 열벡터 하나로 나머지 열벡터들을 생성 가능
- 이는 pivot이 속한 행과 열을 제외한 나머지 행, 열은 독립적이지 않다는 의미

#### Null Space와의 직교성

- Null Space를 구성하는 벡터들 (예: s1, s2 등)과 pivot이 있는 행벡터와의 내적은 항상 0
- 즉, _pivot이 있는 행벡터는 Null Space와 직교_함

_이런 관계들은 선형대수에서 해 공간을 이해하고, 행렬의 구조를 분석할 때 핵심적인 의미를 가짐_


# Rank와 Null Space의 관계

## Rank의 정의와 기본 성질

#### Rank란?

- 어떤 행렬 A의 rank는 그 행렬의 **pivot(피벗)**의 개수를 의미함
- 즉, _rank(A) = 피벗의 개수 = r_

#### Rank 관련 등식

- _rank(A) = r = 독립적인 행의 개수 = 독립적인 열의 개수 = Column Space의 차원_
- r은 A의 행 수 m과 열 수 n을 기준으로 다음을 만족함:
    - _r ≤ m_, _r ≤ n_

#### Rank의 유형

- _r = m_ 이면: full row rank (모든 행이 독립적)
- _r = n_ 이면: full column rank (모든 열이 독립적)

## Rank와 Null Space의 관계

#### 자유변수와 special solution

- 자유변수의 개수 = n - r
- 자유변수 하나마다 하나의 special solution이 존재함
- 즉, _Null Space N(A)는 (n - r)개의 special solution으로 생성된 벡터공간_
    

#### Null Space의 의미

- _N(A) = Ax = 0_을 만족하는 모든 해 x의 집합
- 자유변수들에 따라 달라지는 해의 조합은 모두 Null Space의 원소
- 이는 _N(A)는 (n - r)개의 special solution이 만드는 span_임

## Ax = b 해법 정리 (b ≠ 0)

#### particular solution xp

- 자유변수 열을 모두 0으로 두고, pivot 변수들만으로 Ax = b 해를 구함 → xp

다음과 같은 연립방정식 Ax=bAx = bAx=b를 생각해보자.

$$
\begin{bmatrix} 1 & 2 & 1 & 0 \\ 0 & 0 & 1 & 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} = \begin{bmatrix} 4 \\ 2 \end{bmatrix}
$$
- 피벗 변수: x1,x3x_1, x_3x1​,x3​
- 자유 변수: x2,x4x_2, x_4x2​,x4​

자유변수를 0으로 두고 Ax = b를 풀면:

1. x2=0,x4=0x_2 = 0, x_4 = 0x2​=0,x4​=0
2. 첫 번째 식: x1+2(0)+1(0)=4⇒x1=4x_1 + 2(0) + 1(0) = 4 \Rightarrow x_1 = 4x1​+2(0)+1(0)=4⇒x1​=4
3. 두 번째 식: x3+0=2⇒x3=2x_3 + 0 = 2 \Rightarrow x_3 = 2x3​+0=2⇒x3​=2

따라서 particular solution은:

$$
x_p = \begin{bmatrix} 4 \\ 0 \\ 2 \\ 0 \end{bmatrix}​​
$$

#### homogeneous solution xn (null space)

- Null space에서 자유변수 열에 1, 0을 조합하여 special solution을 구함 → x2, x4, ...
- 이는 Ax = 0을 푸는 것과 같으며, 자유변수가 n-r개면 special solution도 n-r개 존재

#### 전체 해

- x = xp + xn
- 즉, particular solution과 null space의 general solution의 합

#### m = n = r인 경우

- 자유변수가 존재하지 않음 → xn = 0
- 따라서 x = xp
- 이때 xp = A⁻¹ * b
- 즉, 유일해가 존재 (Ax = b 해가 하나)

## Column Space와 Row Space

#### Column Space C(A)

- 열벡터들로 생성되는 벡터공간
- _dim(C(A)) = rank(A) = r_

#### Row Space

- A의 행들로 생성되는 벡터공간
- _Aᵀ의 열공간 = A의 행공간_
- 즉, 전치행렬 Aᵀ을 통해 Row Space를 열벡터 관점으로 볼 수 있음


## 행렬 형태에 따른 해의 개수 분류

#### Case 1: r = m & r = n (정사각행렬, 가역행렬)

- square and invertible
- Ax = b는 유일한 해를 가짐

#### Case 2: r = m & r < n (행이 더 많음: overdetermined)

- short and wide
- Ax = b는 무한히 많은 해를 가짐

#### Case 3: r < m & r = n (열이 더 많음: underdetermined)

- tall and thin
- Ax = b는 해가 없거나 하나 존재함

#### Case 4: r < m & r < n (full rank 아님)

- not full rank
- Ax = b는 해가 없거나 무한히 많음

## overdetermined vs underdetermined

#### Overdetermined system(세로로 긴 행렬)

- 미지수보다 방정식이 많다 → 열 수 ≤ 행 수 (n ≤ m)
- full column rank인 경우 (r = n)
    - 모든 열은 pivot column
    - 자유변수 없음 → special solution 없음
    - N(A)는 0 벡터만 포함 
    - Ax = b가 solvable할 경우 해는 유일함

#### Underdetermined system(가로로 긴 행렬)

- 방정식보다 미지수가 많다 → 열 수 ≥ 행 수 (n ≥ m)
- full row rank인 경우 (r = m)
    - 모든 행이 pivot을 갖는다
    - zero row가 없음 → 행이 독립적임
    - 자유변수가 존재 → Ax = b는 무한히 많은 해를 가질 수 있음

# Basis Vector (기저벡터)

## 정의

- 기저벡터란 특정 공간을 구성하는 가장 **작고 독립적인 벡터 집합**이다.
- 다음 두 조건을 모두 만족해야 한다:
    - 선형독립성: 벡터들 사이에 종속 관계가 없음
    - 공간 생성(Spanning): 벡터들의 선형조합으로 전체 공간을 구성할 수 있음

## 특징

- 기저벡터의 개수는 해당 공간의 **차원(Dimension)**과 같다.
- 기저벡터 집합은 **유일하지 않다**. 다양한 기저 조합이 존재할 수 있다.

## 예시

- R2\mathbb{R}^2R2 공간에서는 두 개의 독립적인 벡터로 모든 벡터를 생성할 수 있다.
- R3\mathbb{R}^3R3 공간에서는 세 개의 독립적인 벡터가 필요하다.

## Overdetermined 시스템

- 정의: 행(방정식)의 수가 열(변수)의 수보다 많은 시스템
- 예: 5×35 \times 35×3 행렬 (5개의 방정식, 3개의 변수)
- 이 경우 **모든 행이 독립일 수는 없음**
    - 최대 3개의 행만 선형독립 가능
    - 나머지 행은 다른 행들의 선형조합으로 표현됨
- 가우스 소거법을 통해 행을 줄이면 영벡터 행이 나타나며, 이는 종속성을 의미함

## Underdetermined 시스템

- 정의: 변수(열)의 수가 방정식(행)의 수보다 많은 시스템
- 자유변수가 존재하며, 보통 **무한히 많은 해**를 가짐
- 하지만 이것이 곧 행이 종속적이라는 의미는 아님. 행이 독립적일 수도 있음

## Null Space와 기저

- 행렬 AAA의 열들이 모두 선형독립이면, Ax=0A\mathbf{x} = \mathbf{0}Ax=0의 해는 **영벡터 하나뿐**
- 이 경우 Null Space는 {0}\{\mathbf{0}\}{0}이며 차원은 0이다

## Pivot과 Basis

- 열 공간(Column Space)의 기저는 **피벗 열에 해당하는 원래의 열벡터들**
- 행 공간(Row Space)의 기저는 **RREF에서 선형 독립적인 행벡터들**
- 피벗이 존재하는 열 또는 행은 해당 공간의 기저를 이룸

## 기타 성질

- Rn\mathbb{R}^nRn 공간을 완전히 채우기 위해서는 **최소 n개의 독립적인 벡터**가 필요
- R2\mathbb{R}^2R2에서 3개의 벡터는 반드시 종속됨
- R3\mathbb{R}^3R3에서 4개의 벡터는 반드시 종속됨

# 직교성(Orthogonality)과 Null Space의 관계

## 직교성의 정의

- 두 벡터의 내적이 0이면, 두 벡터는 직각, 즉 서로 직교한다고 한다.
- 두 벡터가 서로 수직일 때 직교성이 있다고 말한다.

## Null Space와의 관계

- 행렬 A에 대해 아래의 조건을 만족하는 벡터들의 집합을 null space N(A)라고 한다:

$$
A\mathbf{x} = \mathbf{0}
$$

- 이때 벡터 x는 행렬 A의 각 행 벡터와 내적이 0이 되므로, x는 A의 행 공간(row space)에 직교한다.
- 즉, null space는 A의 행 공간의 직교 여공간이다:

$$
N(A) = \text{Row}(A)^\perp
$$

## 직교 여공간의 개념

- 어떤 부분 공간 V의 직교 여공간 Vㅗ는 V에 속한 모든 벡터와 직교하는 벡터들의 집합이다.
- 예시:

$$
N(A) = \text{Row}(A)^\perp \\
N(A^T) = \text{Cal}(A)^\perp
$$

## 벡터의 분해

- 모든 벡터 x는 두 부분으로 나눠서 표현할 수 있다:

$$
\mathbf{x} = \mathbf{x}_{\text{row}} + \mathbf{x}_{\text{null}}
$$

- 여기서 row는 행 공간에 속하고, null은 null space에 속한다.
- 선형 시스템 Ax = b에 대해:

$$
A\mathbf{x} = A(\mathbf{x}_{\text{row}} + \mathbf{x}_{\text{null}}) = A\mathbf{x}_{\text{row}} + A\mathbf{x}_{\text{null}} = \mathbf{b}
$$
## Null space의 구성

- 자유변수의 개수만큼 special solution이 존재하며, 이들은 null space의 기저 벡터가 된다.
- Null space는 이러한 special solution들의 실수 계수 조합으로 구성된다.
- 따라서 null space 자체는 유일한 벡터 공간이지만, 그 기저는 여러 가지가 존재할 수 있다.

*시험에 A를 통해 x의 해를 x = x_row + x_null 꼴로 바꾸는 문제 출제(이후 행렬식으로 묶어 가우스소거법을 통해 해를 구하는 방식도 나올 수 있다.)*


# 투영 (Projection)

벡터를 어떤 **직선, 평면, 또는 더 고차원의 부분공간(Subspace)** 에 **투영**한다는 것은  
그 공간에 **가장 가까운 벡터**를 찾는다는 의미다.

즉, 벡터 b를 대상 공간에 **수직으로 꽂아 만든 벡터**가 투영된 벡터 p 다.

## 투영 수식 예시

벡터가 다음과 같을 때:
$$
b = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}, \quad
a = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}
$$

벡터 \( b \)를 \( a \)에 투영하면,
$$
\hat{x} = \frac{a^T b}{a^T a} = \frac{5}{9}
$$

$$
\hat{p} = \hat{x} a = \frac{5}{9} \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix} = \begin{bmatrix} \frac{5}{9} \\ \frac{10}{9} \\ \frac{10}{9} \end{bmatrix}
$$

## 투영 행렬  P의 성질

- 투영 행렬 공식:

$$
P = \frac{a a^T}{a^T a}
$$

- 벡터 \( b \)를 \( a \) 방향으로 투영한 결과:

$$
p = Pb
$$

- 투영 벡터의 크기:
$$
\|p\| = \|b\| \cos \theta
$$

##  b를 부분공간 S에 투영

- A: 부분공간 S의 기저 행렬
- 투영 결과:
$$
p = Ax = A(A^T A)^{-1} A^T b = Pb
$$

- 오차 벡터:
$$
e = b - p
$$

## 선형 시스템과 투영의 관계

- 최소 제곱 해 x는 다음을 만족:
$$
A^T A \hat{x} = A^T b
$$
- 투영된 벡터는:
$$
p = A \hat{x} = A (A^T A)^{-1} A^T b = Pb
$$


# 최소제곱법 (Least Squares Approximation)

## 문제의 배경

- 선형 방정식 $$A\vec{x} = \vec{b}$$는 항상 해를 가지는 것이 아님

- 해가 존재하지 않는 대표적인 경우:
  - 방정식이 너무 많은 경우 (과잉 결정 시스템)
	$$m > n$$ (행의 수 > 열의 수)
  - b가 C(A) (열공간)에 속하지 않는 경우

## 핵심 아이디어

- 해가 없을 때는 **정확한 해가 아닌, 가장 근사한 해**를 구함
- 즉, $$A\vec{x} = \vec{b}$$를 만족하지 않더라도 오차 $$\vec{e} = A\vec{x} - \vec{b}$$의 크기 $$\|\vec{e}\|$$를 최소화하는 $$\vec{x}$$를 찾음

## 예제: 세 점에 가장 근사한 직선 구하기

- 세 점: (0, 6), (1, 0), (2, 0)
- 직선의 방정식: $$y = C + D \cdot t$$
- 세 점을 식으로 표현하면
	6 = C + D * 0  
	0 = C + D * 1  
	0 = C + D * 2
	가 있다.

#### 행렬 형태

$$
A =
\begin{bmatrix}
1 & 0 \\
1 & 1 \\
1 & 2
\end{bmatrix},
\quad
\vec{x} =
\begin{bmatrix}
C \\
D
\end{bmatrix},
\quad
\vec{b} =
\begin{bmatrix}
6 \\
0 \\
0
\end{bmatrix}
$$

## 일반 해법

- 직접적으로 $$A\vec{x} = \vec{b}$$를 풀 수 없으므로,
- 양변에 $$A^T$$를 곱해 정방행렬을 만듦:

$$
A^T A \vec{x} = A^T \vec{b}
$$

- 이로부터 $$\vec{x}$$를 구함

#### 결과:

$$
\vec{x} =
\begin{bmatrix}
5 \\
-3
\end{bmatrix},
\quad
\vec{p} = A\vec{x} =
\begin{bmatrix}
5 \\
2 \\
-1
\end{bmatrix}
$$

- 즉, 세 점과의 거리 제곱의 합이 최소가 되는 **직선 방정식**은 $$y = 5 - 3t$$

# Gram-Schmidt 정규직교화 (Orthogonalization)

- **Orthogonal (직교)**: 두 벡터의 내적이 0일 때, 서로 직교함$$\vec{v_1} \cdot \vec{v_2} = 0$$
- **Orthonormal (정규직교)**: 직교하고 각 벡터의 노름이 1일 때$$\|\vec{v}\| = 1$$ 이면서 서로 직교

## 정방행렬의 직교성 조건
$$V^T V = I \Rightarrow V^T = V^-1$$ V는 orthonormal 행렬 $$V^{-1} = V^T$$ (정방행렬인 경우)

## 벡터의 반사 (Reflection)

- 벡터 $$\vec{u}$$를 직선 $$y = x$$ 기준으로 반사하려면:
  - $$I - 2\vec{u}\vec{u}^T$$ 를 곱함

## 최소제곱법과 직교 행렬의 관계

- 정규직교 행렬 $$Q$$에 대해 최소제곱 해를 구하면:

$$
\vec{x} = Q^T \vec{b}
$$

$$
\vec{p} = Q \vec{x}
$$

즉, 투영 행렬 P는
$$
P = Q Q^T
$$

## Orthogonal → Orthonormal 변환

- 직교성만 있는 행렬 Q를 정규직교화 하려면 각 열벡터를 ||C(Q)||로 나누면 됨

# Gram-Schmidt 정규직교화 과정과 Orthonormal 행렬의 조건

## Gram-Schmidt 과정 요약

- 주어진 **서로 독립적인 벡터**들을 **정규직교화(Orthonormalization)** 하기 위한 알고리즘
- 순차적으로 벡터를 정규 직교 형태로 변환

### 과정
1. 임의의 선형독립 벡터 3개를 \( \vec{a}, \vec{b}, \vec{c} \)라고 칭함.
2. \( \vec{b} \)에서 \( \vec{a} \) 방향 성분을 제거하여 \( \vec{B} \) 벡터를 만듦  
   → 이는 \( \vec{a} \)와 직교인 벡터
3. $\vec{c}$에서 $\vec{a}, \vec{B}$의 span 성분을 제거하여 $\vec{C}$ 벡터를 만듦  
   → $\vec{a}, \vec{B}$모두와 직교

## 투영 공식 (Projection formula)

1. 벡터 a에 b를 투영 -> B벡터 생성$$ \vec{B} = \vec{b} - \frac{\vec{a}^T \vec{b}}{\vec{a}^T \vec{a}} \vec{a} $$
- 두 벡터가 orthgonal한지 확인(생략가능)$$ \vec{a}^T \vec{B} = 0 $$
1. a,B의 span에 c벡터 투영 -> A(=a), B, C열벡터 생성 -> 묶에서 A행렬 생성$$ \vec{C} = \vec{c} - \left( \frac{\vec{a}^T \vec{c}}{\vec{a}^T \vec{a}} \vec{a} + \frac{\vec{B}^T \vec{c}}{\vec{B}^T \vec{B}} \vec{B} \right) $$

## 정규화 (Normalization)
- $$ \vec{q}_1 = \frac{\vec{a}}{||\vec{a}||} ,  
   \vec{q}_2 = \frac{\vec{B}}{||\vec{B}||} ,  
   \vec{q}_3 = \frac{\vec{C}}{||\vec{C}||} $$
- 이때 $$\{Q =  \vec{q}_1, \vec{q}_2, \vec{q}_3 \}$$는 **orthonormal**한 집합

## QR 분해와 정규직교성

#### 정의
- $A = QR$: 선형독립 열벡터를 갖는 행렬 \( A \)를,  
  - \( Q \): 열이 정규직교(orthonormal)인 행렬 (m × n)
  - \( R \): 상삼각행렬 (n × n)

#### 계산 방법
- $R = Q^T A$
- QR 분해에서 \( Q \)는 Gram-Schmidt를 통해 생성됨

## 정사각 Q 행렬일 때 (n = m)

- $Q^T = Q^{-1}$이 성립
- 이 경우, $A = QR$ →  $A^T A = (QR)^T (QR) = R^T Q^T Q R = R^T R$
  (여기서 $Q^T Q = I$ 이용)
- \( R \)이 상삼각행렬이므로 해를 구할 때 **후방 대입법 (Back Substitution)** 사용 가능

## Orthonormal 조건과 행렬 차원

- Q가 정규직교성을 가지려면:
  - A의 열벡터는 **선형독립**이어야 함
  - 즉, **m ≥ n** 이어야 함 (행 ≥ 열)
- 만약 \( m < n \)이라면,
  - 독립인 열벡터 수가 최대 m이므로
  - n개 열벡터가 **선형독립일 수 없음**
  - 따라서 **orthonormal Q 생성 불가**

## 요약

- **정규직교화(Gram-Schmidt)** 는 선형독립 벡터 집합으로부터 orthonormal한 기저를 만드는 과정
- **QR 분해**는 이 과정을 통해 A = QR로 분해하며,  
  - \( R = Q^T A \)로 계산
- \( Q \)가 정사각 행렬일 경우에만 \( Q^T = Q^{-1} \)가 성립
- \( m < n \)인 행렬은 열벡터가 독립적일 수 없어 QR 분해의 정규직교 Q를 생성할 수 없음

-> orthonormal하지 않은 행렬 A를 이용해 Ax = b꼴을 푸는 것은 매우 복잡함. x = x_row + x_null을 계산해야 하기 때문, 이를 orthonormal하게 만들어 dot,reflection을 간단하게 하여 해를 더 쉽게 찾고자 함.

determinant : 행렬식의 정보를 담은 스칼라 값 -> 역행렬의 존재여부, 역행렬을 계산할 수 있다.

det(A) = ad - bc
det($A^-1$) = 1 / det(A)
$A^-1 = 1/ad-bc[d, -b / -c, a]$
행교환 = det의 sign이 바뀜(1번 -> 1회 바뀜)

